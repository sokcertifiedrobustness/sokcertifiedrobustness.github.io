# SoK: Certified Robustness for Deep Neural Networks

Recently, provable (i.e. certified) adversarial robustness training and verification methods have demonstrated their effectiveness against adversarial attacks. In contrast to empirical robustness and empirical adversarial attacks, the provable robustness verification provides rigorous lower bound of robustness for a given neural network, such that **no** existing or future attacks will attack further. 

This repo contains the leaderboard website of state-of-the-art certified robustness achieved on common datasets.

**Website**: https://sokcertifiedrobustness.github.io/

**Accompanying [SoK paper](https://arxiv.org/abs/2009.04131) is accepted by IEEE S&P (Oakland) 2023!**

If you find this repo helpful, please consider cite our paper:
```
@inproceedings{li2023sok,
    title={{SoK}: Certified Robustness for Deep Neural Networks},
    author={Linyi Li and Tao Xie and Bo Li},
    booktitle={44th {IEEE} Symposium on Security and Privacy, {SP} 2023, San Francisco, CA, USA, 22-26 May 2023},
    publisher={IEEE},
    year={2023}
}
```

**Accompanying open-source toolbox**: https://github.com/AI-secure/VeriGauge

## Announcing your great result?

Feel free to directly edit `_data/board.yml` in the repo and send a pull request.

---

Maintained by Linyi.
